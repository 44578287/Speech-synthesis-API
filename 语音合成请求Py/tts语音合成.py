# coding=utf-8

import os
import sys
os.environ['REQUESTS_CA_BUNDLE'] = os.path.join(os.path.dirname(sys.argv[0]), 'cacert.pem')
import hashlib
import requests
import websockets
import asyncio
from datetime import datetime
import time
import re
import uuid
import argparse


'''命令行参数解析'''
def parseArgs():
    parser = argparse.ArgumentParser(description='text2speech')
    parser.add_argument('--md5', dest='md5', help='计算md5',type=str, required=False)
    parser.add_argument('--input', dest='input',help='SSML(语音合成标记语言)的路径', type=str, required=False)

    parser.add_argument('--text', dest='text',help='合成文本', type=str, required=False)
    parser.add_argument('--name', dest='name', help='声音名',type=str, required=False)
    parser.add_argument('--style', dest='style', help='说话风格',type=str, required=False)
    parser.add_argument('--rate', dest='rate',help='语气', type=str, required=False)
    parser.add_argument('--pitch', dest='pitch', help='音调',type=str, required=False)

    parser.add_argument('--output', dest='output',help='保存mp3文件的路径', type=str, required=False)
    args = parser.parse_args()
    return args

# 固定时间以配合美国人的说法
def hr_cr(hr):
    corrected = (hr - 1) % 24
    return str(corrected)


# 在正确的地方添加零，即22:1:5 -> 22:01:05
def fr(input_string):
    corr = ''
    i = 2 - len(input_string)
    while (i > 0):
        corr += '0'
        i -= 1
    return corr + input_string


# 生成的X-Timestamp都有正确的格式
def getXTime():
    now = datetime.now()
    return fr(str(now.year)) + '-' + fr(str(now.month)) + '-' + fr(str(now.day)) + 'T' + fr(hr_cr(int(now.hour))) + ':' + fr(str(now.minute)) + ':' + fr(str(now.second)) + '.' + str(now.microsecond)[:3] + 'Z'


# 用于与websocket实际通信的异步函数
async def transferMsTTSData(SSML_text, outputPath):
    # endpoint1 = "https://azure.microsoft.com/en-gb/services/cognitive-services/text-to-speech/"
    # r = requests.get(endpoint1)
    # main_web_content = r.text
    # # They hid the Auth key assignment for the websocket in the main body of the webpage....
    # token_expr = re.compile('token: \"(.*?)\"', re.DOTALL)
    # Auth_Token = re.findall(token_expr, main_web_content)[0]
    # req_id = str('%032x' % random.getrandbits(128)).upper()
    # req_id is generated by uuid.
    req_id = uuid.uuid4().hex.upper()
    #print(req_id)
    # wss://eastus.api.speech.microsoft.com/cognitiveservices/websocket/v1?TrafficType=AzureDemo&Authorization=bearer%20undefined&X-ConnectionId=577D1E595EEB45979BA26C056A519073
    # endpoint2 = "wss://eastus.tts.speech.microsoft.com/cognitiveservices/websocket/v1?Authorization=" + \
    #     Auth_Token + "&X-ConnectionId=" + req_id
    # 目前该接口没有认证可能很快失效
    endpoint2 = f"wss://eastus.api.speech.microsoft.com/cognitiveservices/websocket/v1?TrafficType=AzureDemo&Authorization=bearer%20undefined&X-ConnectionId={req_id}"
    async with websockets.connect(endpoint2) as websocket:
        payload_1 = '{"context":{"system":{"name":"SpeechSDK","version":"1.12.1-rc.1","build":"JavaScript","lang":"JavaScript","os":{"platform":"Browser/Linux x86_64","name":"Mozilla/5.0 (X11; Linux x86_64; rv:78.0) Gecko/20100101 Firefox/78.0","version":"5.0 (X11)"}}}}'
        message_1 = 'Path : speech.config\r\nX-RequestId: ' + req_id + '\r\nX-Timestamp: ' + \
            getXTime() + '\r\nContent-Type: application/json\r\n\r\n' + payload_1
        await websocket.send(message_1)

        payload_2 = '{"synthesis":{"audio":{"metadataOptions":{"sentenceBoundaryEnabled":false,"wordBoundaryEnabled":false},"outputFormat":"audio-16khz-32kbitrate-mono-mp3"}}}'
        message_2 = 'Path : synthesis.context\r\nX-RequestId: ' + req_id + '\r\nX-Timestamp: ' + \
            getXTime() + '\r\nContent-Type: application/json\r\n\r\n' + payload_2
        await websocket.send(message_2)

        # payload_3 = '<speak xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts" xmlns:emo="http://www.w3.org/2009/10/emotionml" version="1.0" xml:lang="en-US"><voice name="' + voice + '"><mstts:express-as style="General"><prosody rate="'+spd+'%" pitch="'+ptc+'%">'+ msg_content +'</prosody></mstts:express-as></voice></speak>'
        payload_3 = SSML_text
        message_3 = 'Path: ssml\r\nX-RequestId: ' + req_id + '\r\nX-Timestamp: ' + \
            getXTime() + '\r\nContent-Type: application/ssml+xml\r\n\r\n' + payload_3
        await websocket.send(message_3)

        # Checks for close connection message
        end_resp_pat = re.compile('Path:turn.end')
        audio_stream = b''
        while(True):
            response = await websocket.recv()
            #print('receiving...')
            # Make sure the message isn't telling us to stop
            if (re.search(end_resp_pat, str(response)) == None):
                # Check if our response is text data or the audio bytes
                if type(response) == type(bytes()):
                    # Extract binary data
                    try:
                        needle = b'Path:audio\r\n'
                        start_ind = response.find(needle) + len(needle)
                        audio_stream += response[start_ind:]
                    except:
                        pass
            else:
                break
        with open(f'{outputPath}.mp3', 'wb') as audio_out:
            audio_out.write(audio_stream)


async def mainSeq(SSML_text, outputPath):
    await transferMsTTSData(SSML_text, outputPath)


def get_SSML(path):
    with open(path, 'r', encoding='utf-8') as f:
        return f.read()


def 生成SMMML文本(文本内容="无内容", 声音名="zh-CN-XiaoxiaoNeural", 说话风格="General", 语速="0", 音调="0"):
    SMML文本 = ('<speak xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="http://www.w3.org/2001/mstts" xmlns:emo="http://www.w3.org/2009/10/emotionml" version="1.0" xml:lang="en-US">'+'\r\n'
              + '<voice name="'+声音名+'">'+'\r\n'
              + '<mstts:express-as style="'+说话风格+'">'+'\r\n'
              + '<prosody rate="'+语速+'%" pitch="'+音调+'%">'+'\r\n'
              + 文本内容+'\r\n'
              + '</prosody>'
              + '</mstts:express-as>'
              + '</voice>'
              + '</speak>')
    return SMML文本


#获取文件MD5
def file_hash(file_path: str, hash_method) -> str:
    if not os.path.isfile(file_path):
        print('文件不存在。')
        return ''
    h = hash_method()
    with open(file_path, 'rb') as f:
        while b := f.read(8192):
            h.update(b)
    return h.hexdigest()


def str_hash(content: str, hash_method, encoding: str = 'UTF-8') -> str:
    return hash_method(content.encode(encoding)).hexdigest()

def file_md5(file_path: str) -> str:
    return file_hash(file_path, hashlib.md5)

def str_md5(content: str, encoding: str = 'UTF-8') -> str:
    return str_hash(content, hashlib.md5, encoding)

#主程序转类
class 语音合成调用():
    #获取SSML内容
    SSML路径 = ""
    #输出路径
    输出路径 = ""
    #获取文件
    def 合成():
        SSML内容 = get_SSML(语音合成调用.SSML路径)
        asyncio.get_event_loop().run_until_complete(
            mainSeq(SSML内容, 语音合成调用.输出路径))
        print('completed')
        return "完成!"


#主程序
if __name__ == "__main__":
    args = parseArgs()
    #SSML_text = get_SSML(args.input)
    if(args.input or args.text):
        SSML_text = 生成SMMML文本(args.text, args.name,args.style, args.rate, args.pitch)
    #SSML_text = 生成SMMML文本(args.text)
    #print(SSML_text)
        output_path = args.output if args.output else args.name + "_" + args.style + "_" + args.rate + "_" + args.pitch + "_" + str_md5(args.text) + "_"
    #print(output_path)
        asyncio.get_event_loop().run_until_complete(mainSeq(SSML_text, output_path))
        print(output_path+".mp3")
    #print(file_md5(output_path+".mp3")+".mp3")
    #os.rename(output_path+".mp3", file_md5(output_path+".mp3")+".mp3")
    #print('completed')
    if(args.md5):
        print(str_md5(args.md5))
    # python tts语音合成.py --input SSML.xml
    # python tts语音合成.py --input SSML.xml --output 保存文件名
    # python tts语音合成.py --text 测试测试
    #python tts语音合成.py --text C#调用测试 --name zh-CN-XiaoxiaoNeural --style General --rate 0 --pitch 0
